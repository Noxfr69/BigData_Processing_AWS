# Big Data Processing on AWS Cloud

## Overview

This project is designed to perform big data processing using AWS cloud services, Spark, and PySpark on an EMR cluster. Resource management is handled using AWS CLI and S3. This repository consists of two notebooks, one for local testing with Spark and the other one to be run on an Amazon EMR cluster.

## Features

### AWS Services
- EMR (Amazon Elastic MapReduce)
- EC2 (Amazon Elastic Compute Cloud)
- S3 (Amazon Simple Storage Service)

### Big Data Processing
- Spark
- PySpark
- PySpark PCA

### Resource Management
- AWS CLI (Command Line Interface)

## Notebooks

1. [Local_Spark_Testing](https://github.com/Noxfr69/BigData_Processing_AWS/blob/main/Local_spark_notebook.ipynb): This notebook is designed for local version testing using Spark.
2. [Amazon_EMR_Cluster](https://github.com/Noxfr69/BigData_Processing_AWS/blob/main/EMR/EMR_notebook.ipynb): This notebook is meant to be run on an Amazon EMR cluster for scalable data processing.


